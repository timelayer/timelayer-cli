[English](README.md) | [ç®€ä½“ä¸­æ–‡](README.zh-CN.md)

# ğŸ§  TimeLayer CLI

> A local-first AI CLI designed for long-term thinking and memory accumulation.

TimeLayer CLI is a **local-first personal AI system**. Its goal is not short-lived Q&A sessions, but:

* Long-term usage
* Continuous recording
* Reflection and summarization
* Building a truly cumulative personal memory system

> If ChatGPT forgets you â€” this wonâ€™t.

---

## 1ï¸âƒ£ Why TimeLayer CLI?

Most existing AI tools have inherent limitations:

* Strong dependency on cloud services
* No long-term state
* Session-based interaction
* Data and behavior are not auditable

These tools are excellent for **short conversations**, but poorly suited for:

* Long-term learning
* Continuous writing
* Technical knowledge accumulation
* Personal knowledge archiving

The goal of TimeLayer CLI is simple:

> **Give AI continuity, instead of starting from zero every day.**

---

## 2ï¸âƒ£ This Is Not a Chatbot

**This is not a chatbot.**
**It is a long-running personal memory system.**

Chat is only one input method â€” not the essence of the system.

The system focuses on:

* What you care about over time
* What you repeatedly think about
* Questions that keep reappearing
* How your understanding evolves

---

## 3ï¸âƒ£ Features

### ğŸ—¨ï¸ Contextual Chat (`/chat`)

* Short-term conversational flow
* Sliding context window
* No guarantee of historical completeness

### ğŸ§  Memory Q&A (`/ask`)

* Oriented toward long-term memory
* Answers questions using *your own historical data*
* Semantic search instead of keyword matching

### ğŸ’¾ Persistent Memory System

* Immutable raw logs in JSONL (fact layer)
* Structured long-term memory stored in SQLite
* Daily / Weekly / Monthly multi-level abstraction

### ğŸ” Semantic Search

* Local embeddings
* SQLite-based vector index
* Can be fully rebuilt from logs at any time

### ğŸ” Fully Local & Privacy-First

* No cloud calls
* No telemetry
* No accounts
* All data stays under your control

---

## 4ï¸âƒ£ Architecture Overview

```
User
 â”‚
 â–¼
CLI (Go)
 â”‚
 â”œâ”€ /chat   Short-term dialogue
 â”œâ”€ /ask    Long-term memory Q&A
 â”œâ”€ Logging & reflection scheduling
 â”‚
 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚               â”‚
 â–¼               â–¼
llama.cpp        Ollama
(Text generation) (Embeddings)
 â”‚               â”‚
 â–¼               â–¼
GGUF models      Vector representations
(Local)           â”‚
                  â–¼
            SQLite (memory.sqlite)
            â”œâ”€ Vector index
            â”œâ”€ Fact summaries
            â””â”€ Long-term user traits
```

> llama.cpp is responsible for *generation*, Ollama for *understanding and retrieval*, and the CLI orchestrates time and memory.

---

## 5ï¸âƒ£ Source Tree

```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ README.zh-CN.md
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ local-ai/
â”‚       â””â”€â”€ main.go
â”œâ”€â”€ internal/
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ run.go
â”‚       â”œâ”€â”€ config.go
â”‚       â”œâ”€â”€ llm.go
â”‚       â”œâ”€â”€ chat*.go
â”‚       â”œâ”€â”€ ask.go
â”‚       â”œâ”€â”€ search.go
â”‚       â”œâ”€â”€ logger.go
â”‚       â”œâ”€â”€ db.go
â”‚       â”œâ”€â”€ index_text.go
â”‚       â”œâ”€â”€ summary_daily.go
â”‚       â”œâ”€â”€ summary_weekly.go
â”‚       â”œâ”€â”€ summary_monthly.go
â”‚       â”œâ”€â”€ user_fact.go
â”‚       â””â”€â”€ tts.go
```

---

## 6ï¸âƒ£ âš™ï¸ Environment & Dependencies (Required)

### Supported Platforms

* macOS (Intel / Apple Silicon)
* Linux (x86_64 / ARM64)

> Windows is supported via WSL2 only.

### Go

* Go **1.21+**

```bash
go version
```

### llama.cpp (Text Generation)

```bash
brew install llama.cpp
llama-cli --version
```

### Ollama (Embeddings â€” **Required**)

> The current version **requires Ollama for local embedding services**, used for:
>
> * Semantic search
> * `/ask` memory retrieval
> * Long-term memory vectorization
>
> **If Ollama is not running, the memory system will not function.**

```bash
brew install ollama
ollama serve
ollama pull nomic-embed-text
```

### GGUF Models

```text
models/
â”œâ”€â”€ qwen2.5-7b-instruct-q5_k_m-00001-of-00002.gguf
â”œâ”€â”€ qwen2.5-7b-instruct-q5_k_m-00002-of-00002.gguf
```

### Directory Initialization

```bash
mkdir -p ~/local-ai/{logs,memory,models,prompts}
```

### Start llama-server (Recommended)

```bash
llama-server \
  -m models/qwen2.5-7b-instruct-q5_k_m-00001-of-00002.gguf \
  --port 8080
```

---

## 7ï¸âƒ£ Local Data & Memory Layout (Real Runtime State)

```
.
â”œâ”€â”€ logs
â”‚   â”œâ”€â”€ 2025-12-24.daily.json
â”‚   â”œâ”€â”€ 2025-12-24.jsonl
â”‚   â””â”€â”€ archive
â”œâ”€â”€ memory
â”‚   â””â”€â”€ memory.sqlite
â”œâ”€â”€ models
â”‚   â”œâ”€â”€ qwen2.5-7b-instruct-q5_k_m-00001-of-00002.gguf
â”‚   â””â”€â”€ qwen2.5-7b-instruct-q5_k_m-00002-of-00002.gguf
â””â”€â”€ prompts
    â”œâ”€â”€ daily.txt
    â”œâ”€â”€ weekly.txt
    â””â”€â”€ monthly.txt
```

### `logs/` â€” Immutable Fact Layer

* JSONL append-only timeline of all interactions
* `*.daily.json` contains daily reflective abstractions

### `memory/` â€” Long-Term Memory Layer

* SQLite database
* Can be fully rebuilt from logs at any time

### `prompts/` â€” Stable Cognitive Templates

* Separate prompts for daily / weekly / monthly reflection
* Prompts are part of system behavior and should be treated as code

---

## 8ï¸âƒ£ Usage Guide

After starting the program, TimeLayer CLI enters an interactive REPL-like interface.

### Basic Interaction

* Type plain text and press Enter to chat with the model
* Each input/output is automatically recorded into the immutable log

### Commands

* `/chat`
  Continue normal conversational interaction using short-term sliding context.

* `/ask <question>`
  Ask questions against your **long-term memory**. The system performs semantic search over historical data and injects the most relevant memories before generation.

* `/daily`
  Trigger daily reflection and abstraction manually (normally auto-triggered).

* `/weekly`
  Generate or update the current weekly summary.

* `/monthly`
  Generate or update the current monthly abstraction.

* `/remember <fact>`
  Explicitly teach the system a confirmed fact. The fact will be written into the immutable log and persisted through daily abstraction, making it retrievable via `/ask`.

* `/forget <fact>`
  Explicitly retract a previously remembered fact. This does not delete history, but records a cognitive retraction that will override the earlier fact in future reasoning.

* `/exit` or `Ctrl+C`
  Exit the program safely.

> Normal chat does not automatically become memory. Only logged and abstracted content participates in long-term retrieval.

---

## 9ï¸âƒ£ Quick Start

```bash
go run ./cmd/local-ai/main.go
```

---

## ğŸ§­ Why TimeLayer Uses GPLv3

TimeLayer is built around a simple but firm belief:  
**software that preserves long-term thinking and memory should itself remain free and transparent.**

We choose the GNU General Public License v3.0 (GPLv3) to ensure that:

- Everyone is free to use, study, modify, and redistribute TimeLayer.
- Improvements and derivative works remain open and benefit the community.
- No one can take the core ideas of TimeLayer, close the source, and turn them into a proprietary product.

GPLv3 is not chosen to restrict usage, but to protect freedom â€”  
the freedom of users, contributors, and future maintainers.

TimeLayer is designed to be a long-term system.  
GPLv3 helps ensure that this long-term value cannot be extracted and locked away.


## ğŸ“œ License

This project is licensed under the **GNU General Public License v3.0 (GPLv3)**.

Any derivative work or redistribution must be released under the same license,
with full source code made available.

See the [LICENSE](LICENSE) file for details.


---

**If you are looking for a personal AI that can accompany you for many years, this project is built for exactly that purpose.**
